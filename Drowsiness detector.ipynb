{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAKHAR .LAPTOP-5EKIAHKD\\Anaconda3\\envs\\prem\\lib\\site-packages\\ipykernel_launcher.py:72: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "#cascade_path='haarcascade_frontalface_default.xml'\n",
    "#cascade = cv2.CascadeClassifier(cascade_path)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "\n",
    "def get_landmarks(im):\n",
    "    rects = detector(im, 1)\n",
    "\n",
    "    if len(rects) > 1:\n",
    "        return \"error\"\n",
    "    if len(rects) == 0:\n",
    "        return \"error\"\n",
    "    return np.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "\n",
    "def annotate_landmarks(im, landmarks):\n",
    "    #Overlays the landmark points on the image itself\n",
    "    \n",
    "    im = im.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "       pos = (point[0, 0], point[0, 1])\n",
    "       cv2.putText(im, str(idx), pos,\n",
    "                   fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                fontScale=0.4,\n",
    "                  color=(0, 0, 255))\n",
    "       cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
    "    return im\n",
    "\n",
    "def top_lip(landmarks):\n",
    "    top_lip_pts = []\n",
    "    for i in range(50,53):\n",
    "        top_lip_pts.append(landmarks[i])\n",
    "    for i in range(61,64):\n",
    "        top_lip_pts.append(landmarks[i])\n",
    "    top_lip_all_pts = np.squeeze(np.asarray(top_lip_pts))\n",
    "    top_lip_mean = np.mean(top_lip_pts, axis=0)\n",
    "    return int(top_lip_mean[:,1])\n",
    "def left_eye(landmarks):\n",
    "    left_point=[]\n",
    "    for i in range(36,38):\n",
    "        left_point.append(landmarks[i])\n",
    "    left_all_points = np.squeeze(np.asarray(left_point))\n",
    "    left_point_mean = np.mean(left_all_points, axis=0)  \n",
    "    return int(left_point_mean[1])\n",
    "def left_bottom_eye(landmarks):\n",
    "    left_bottom_point=[]\n",
    "    for i in range(39,41):\n",
    "        left_bottom_point.append(landmarks[i])\n",
    "    left_bottom_all_points = np.squeeze(np.asarray(left_bottom_point))\n",
    "    left_bottom_point_mean = np.mean(left_bottom_all_points, axis=0)  \n",
    "    return int(left_bottom_point_mean[1])    \n",
    "def bottom_lip(landmarks):\n",
    "    bottom_lip_pts = []\n",
    "    for i in range(65,68):\n",
    "        bottom_lip_pts.append(landmarks[i])\n",
    "    for i in range(56,59):\n",
    "        bottom_lip_pts.append(landmarks[i])\n",
    "    bottom_lip_all_pts = np.squeeze(np.asarray(bottom_lip_pts))\n",
    "    bottom_lip_mean = np.mean(bottom_lip_pts, axis=0)\n",
    "    return int(bottom_lip_mean[:,1])\n",
    "\n",
    "def mouth_open(image):\n",
    "    landmarks = get_landmarks(image)\n",
    "    \n",
    "    if landmarks == \"error\":\n",
    "        return image, 0,0\n",
    "    \n",
    "    image_with_landmarks = annotate_landmarks(image, landmarks)\n",
    "    top_lip_center = top_lip(landmarks) #upper lip(lop and bottom) \n",
    "                                        #lower lip(lop and bottom) \n",
    "    bottom_lip_center = bottom_lip(landmarks)\n",
    "    lip_distance = abs(top_lip_center - bottom_lip_center)\n",
    "    #image_with_landmarks = annotate_landmarks(image, landmarks)\n",
    "    left_top = left_eye(landmarks) #upper lip(lop and bottom) \n",
    "                                        #lower lip(lop and bottom) \n",
    "    left_bottom = left_bottom_eye(landmarks)\n",
    "    eyes_distance = abs(left_top - left_bottom)\n",
    "    return image_with_landmarks, lip_distance,eyes_distance\n",
    "#def eyes_close(image):\n",
    " #   landmarks = get_landmarks(image)\n",
    "    \n",
    " #   if landmarks == \"error\":\n",
    "  #      return image, 0\n",
    "    \n",
    "  #  image_with_landmarks = annotate_landmarks(image, landmarks)\n",
    "   # left_top = left_eye(landmarks) #upper lip(lop and bottom) \n",
    "                                        #lower lip(lop and bottom) \n",
    "   # left_bottom = left_bottom_eye(landmarks)\n",
    "   # eyes_distance = abs(left_top - left_bottom)\n",
    "   # return image_with_landmarks, eyes_distance\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "yawns = 0\n",
    "yawn_status = False \n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()   \n",
    "    image_landmarks,lip_distance,eyes_distance = mouth_open(frame)\n",
    "    #image_landmarks,eyes_distance=eyes_close(frame)\n",
    "    prev_yawn_status = yawn_status  \n",
    "    if eyes_distance>5:\n",
    "        cv2.putText(frame, \"Subject eyes open\", (100,450), \n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,0),3)\n",
    "    else:\n",
    "        cv2.putText(frame, \"Subject eyes close\", (100,450), \n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,255),3)\n",
    "    if lip_distance > 20:\n",
    "        yawn_status = True \n",
    "        \n",
    "        cv2.putText(frame, \"Subject is Yawning\", (50,150), \n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1,(0,0,255),2)\n",
    "        \n",
    "\n",
    "        output_text = \" Yawn Count: \" + str(yawns + 1)\n",
    "\n",
    "        cv2.putText(frame, output_text, (50,50),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,127),2)\n",
    "        \n",
    "    else:\n",
    "        yawn_status = False \n",
    "         \n",
    "    if prev_yawn_status == True and yawn_status == False: # this counts actual yawns\n",
    "        yawns += 1\n",
    "   \n",
    "    cv2.imshow('Live Landmarks', image_landmarks )\n",
    "    cv2.imshow('Yawn and eyes Detection', frame )\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prem] *",
   "language": "python",
   "name": "conda-env-prem-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
